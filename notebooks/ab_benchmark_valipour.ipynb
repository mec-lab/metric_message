{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sympy import lambdify\n",
    "import sympy as sp\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "import omegaconf\n",
    "\n",
    "from symbolicgpt.models import GPT, GPTConfig, PointNetConfig\n",
    "from symbolicgpt.utils import processDataFiles, CharDataset,\\\n",
    "        sample_from_model\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "#\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cca678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for running benchmarks\n",
    "\n",
    "distribution_type = \"uniform\"\n",
    "# for normal distribution, use mean and standard deviation.\n",
    "# for uniform distribution the range is the min and max values\n",
    "distribution_range = [-.990, 1.0]\n",
    "number_points = 20\n",
    "number_trials = 100 # seeds will be trial number\n",
    "logging = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_1 = \"sin(x * exp(x))\"\n",
    "complex_2 = \"x + log(x**4)\"\n",
    "complex_3 = \"1+x*sin(1/x)\"\n",
    "complex_4 = \"sqrt(x**3) * log(x**2)\"\n",
    "complex_5 = \"(x+x**3) / (1+x*cos(x**2))\"\n",
    "complex_6 = \"x / (sqrt(x**2 + sin(x)))\"\n",
    "complex_7 = \"cos((x+sin(x))/ (x**3+x*log(x**2)))\"\n",
    "complex_8 = \"(exp(x) * (1+sqrt(1+x) + cos(x**2)))/ x**2\"\n",
    "\n",
    "\n",
    "ab_support = [\"-5 5\",\\\n",
    "                  \"-5 5\",\\\n",
    "                  \"-5 5\",\\\n",
    "                  \"-5 5\",\\\n",
    "                  \"-5 5\",\\\n",
    "                  \"-5 5\",\\\n",
    "                  \"-5 5\",\\\n",
    "                  \"-5 5\",\\\n",
    "                 ]\n",
    "\n",
    "\n",
    "sample_meta = {complex_1: (-5., 5., number_trials),\n",
    "               complex_2: (-5., 5., number_trials),\n",
    "               complex_3: (-5., 5., number_trials),\n",
    "               complex_4: (-5., 5., number_trials),\n",
    "               complex_5: (-2., 1., number_trials),\n",
    "               complex_6: (-5., 5., number_trials),\n",
    "               complex_7: (-5., 5., number_trials),\n",
    "               complex_8: (.1, 5., number_trials)\n",
    "              }\n",
    "\n",
    "benchmark_eqns = [complex_1, complex_2, complex_3, complex_4, \\\n",
    "        complex_5, complex_6, complex_7, complex_8]\n",
    "\n",
    "set_name = \"AB_Complex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize equations\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "    x = np.arange(bottom, top, step_size)\n",
    "    \n",
    "    plt.plot(x, my_fn(x), label = f\"{fn}-{1+number}\")\n",
    "    print(x.shape, my_fn(x).shape)\n",
    "    print(f\" {1+number} {sp.simplify(fn)} \\n\")\n",
    "    print(f\"  {sp.expand(fn)} \\n\")\n",
    "    print(fn)\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(f\"{set_name} benchmark equations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from symbolicGPT.py in Valipour\n",
    "\n",
    "embeddingSize = 512\n",
    "numPoints = [20,21]\n",
    "numVars = 1\n",
    "numYs = 1\n",
    "method = \"EMB_SUM\"\n",
    "variableEmbedding = \"NOT_VAR\"\n",
    "\n",
    "# create the model                                                              \n",
    "pconf = PointNetConfig(embeddingSize=embeddingSize,                             \n",
    "                       numberofPoints=numPoints[1]-1,                           \n",
    "                       numberofVars=numVars,                                    \n",
    "                       numberofYs=numYs,                                        \n",
    "                       method=method,                                           \n",
    "                       variableEmbedding=variableEmbedding)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blockSize = 64\n",
    "maxNumFiles = 100\n",
    "const_range = [-2.1, 2.1]\n",
    "decimals = 8\n",
    "trainRange = [-3.0,3.0]\n",
    "\n",
    "target = \"Skeleton\"\n",
    "addVars = True if variableEmbedding == 'STR_VAR' else False\n",
    "path = os.path.join(\"./symbolicgpt\", \"datasets\", \"exp_test_temp\", \"Train\", \"*.json\")\n",
    "my_device = torch.device(\"cpu\")\n",
    "\n",
    "files = glob.glob(path)[:maxNumFiles]                                       \n",
    "text = processDataFiles(files) \n",
    "\n",
    "chars = sorted(list(set(text))+['_','T','<','>',':']) # extract unique characters from the text before converting the text to a list, # T is for the test data\n",
    "text = text.split('\\n') # convert the raw text to a set of examples         \n",
    "trainText = text[:-1] if len(text[-1]) == 0 else text    \n",
    "vocab_size = 49\n",
    "\n",
    "train_dataset = CharDataset(text, blockSize, chars, numVars=numVars,        \n",
    "                numYs=numYs, numPoints=numPoints, target=target, addVars=addVars, \n",
    "                const_range=const_range, xRange=trainRange, decimals=decimals, augment=False)\n",
    "\n",
    "                 \n",
    "mconf = GPTConfig(vocab_size, blockSize,           \n",
    "                  n_layer=8, n_head=8, n_embd=embeddingSize,                    \n",
    "                  padding_idx=train_dataset.paddingID)   \n",
    "\n",
    "model = GPT(mconf, pconf)      \n",
    "\n",
    "# # load the best model before training                                         \n",
    "\n",
    "model_name = \"XYE_1Var_30-31Points_512EmbeddingSize_SymbolicGPT_GPT_PT_EMB_SUM_Skeleton_Padding_NOT_VAR_MINIMIZE.pt\"\n",
    "model_path = os.path.join(\"symbolicgpt\", \"Models\", model_name)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))                                   \n",
    "model = model.eval().to(my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0dfa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict = {index:elem for index, elem in enumerate(chars[:])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa537ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173145e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variables = torch.tensor([1])\n",
    "temperature = 1.0\n",
    "top_k = 0.0\n",
    "top_p = 0.7\n",
    "do_sample = False\n",
    "inputs = torch.tensor([[23]]) # assume 23 is start token '<' \n",
    "model.to(torch.device(\"cpu\"));\n",
    "\n",
    "accuracies = []\n",
    "all_mses = []\n",
    "all_mse_sds = []\n",
    "\n",
    "catastrophic_failure_count = 0\n",
    "for hh, eqn in enumerate(benchmark_eqns):\n",
    "    equivalents = []\n",
    "    mses = []\n",
    "    for trial in range(number_trials):\n",
    "        \n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "        \n",
    "        my_fn = sp.lambdify(\"x\", expr=eqn)\n",
    "        \n",
    "        (bottom, top, number_samples) = sample_meta[eqn]\n",
    "        x = np.random.rand(number_samples, 1) \\\n",
    "                * (top-bottom) \\\n",
    "                + bottom\n",
    "        \n",
    "        y = my_fn(x)\n",
    "        \n",
    "        x = torch.tensor(x.transpose(1,0)[None,:,:])\n",
    "        y = torch.tensor(y.transpose(1,0)[None,:,:])\n",
    "        \n",
    "        points = torch.cat([x,y], dim=1).float()\n",
    "        \n",
    "        \n",
    "        pred_outputs = sample_from_model(model, inputs, \n",
    "            blockSize, points=points,\\\n",
    "            variables=variables, temperature=temperature,\\\n",
    "            sample=do_sample, top_k=top_k, top_p=top_p)\n",
    "        \n",
    "        string_output = [char_dict[elem.item()] for elem in pred_outputs[0]]\n",
    "        pred_skeleton = \"\".join(string_output).replace(\"s\",\"x\").replace(\"q\",\"s\").split(\">\")[0][1:]\n",
    "              \n",
    "        pred_expression = pred_skeleton.replace(\"C\",\"1.\").replace(\"x1\",\"x\")\n",
    "        print(pred_expression)\n",
    "        \n",
    "        try:\n",
    "            tgt_eqn = sp.simplify(eqn)\n",
    "            best_eqn = sp.simplify(pred_expression)\n",
    "            print(best_eqn)\n",
    "\n",
    "            tgt_fn = sp.lambdify(\"x\", expr=eqn)\n",
    "            best_fn = sp.lambdify(\"x\", expr=pred_expression.replace(\"x1\",\"x\"))\n",
    "\n",
    "            is_correct = 1.0 * (sp.simplify(best_eqn - tgt_eqn) == 0) \n",
    "            is_correct += 1.0 * (sp.simplify(sp.simplify(best_eqn-1.0) - tgt_eqn) == 0)\n",
    "            \n",
    "            my_mse_1 = np.mean((tgt_fn(x.numpy()) - best_fn(x.numpy()))**2)\n",
    "            my_mse_0 = np.mean((tgt_fn(x.numpy()) - (best_fn(x.numpy())-1.0) )**2)\n",
    "            \n",
    "            mses.append(min([my_mse_1, my_mse_0]))\n",
    "            \n",
    "        except:\n",
    "            error_msg = f\"evaluation failed with predicted expression {pred_skeleton}.\"\n",
    "            wright = \"incorrect\"\n",
    "            \n",
    "            catastrophic_failure_count += 1\n",
    "            is_correct = 0\n",
    "            \n",
    "        equivalents.append(is_correct)\n",
    "        \n",
    "        wright = \"correct\" if equivalents[-1] else \"incorrect\"\n",
    "\n",
    "        correct = 1 if equivalents[-1] else 0\n",
    "        \n",
    "        try:\n",
    "            msg = f\"eqn {hh+1}, trial {trial} predicted {wright} equation: \\n    predicted: {best_eqn}\\n\"\n",
    "            msg +=f\"    target   : {tgt_eqn}\"\n",
    "            msg += f\" with mse {mses[-1]:.3}\\n\"\n",
    "        except:\n",
    "            msg = \"\"\n",
    "        print(msg)\n",
    "\n",
    "    msg = f\"accuracy for equation {hh+1}: {np.mean(equivalents)}\"\\\n",
    "            f\" with mean mse: {np.mean(mses):3}, running total failure count: {catastrophic_failure_count}\\n\"\n",
    "    print(msg)\n",
    "    accuracies.append(np.mean(equivalents))\n",
    "    all_mses.append(np.mean(mses))\n",
    "    all_mse_sds.append(np.std(mses))\n",
    "    \n",
    "failure_msg = f\"\\nTotal failure count: {catastrophic_failure_count}, of {len(benchmark_eqns)*number_trials}\"\n",
    "failure_msg += f\" = {catastrophic_failure_count / (len(benchmark_eqns)*number_trials)}\"\n",
    "print(failure_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af30f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_method = \"Valipour\"\n",
    "msg = f\"{my_method} accuracies\\n\"\n",
    "\n",
    "for ii, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    msg += f\"\\n  Nguyen-{ii+1},  accuracy: {accuracies[ii]:5f}, mse: {all_mses[ii]:.5} +/- {all_mse_sds[ii]:.5}\\n\"\n",
    "    \n",
    "    msg += f\"  {sp.expand(eqn)} \\n\"\n",
    "\n",
    "print(failure_msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Total failure count: 231, of 800 = 0.28875\n",
    "Valipour accuracies\n",
    "\n",
    "  Nguyen-1,  accuracy: 0.000000, mse: 0.1345 +/- 0.090686\n",
    "  x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-2,  accuracy: 0.050000, mse: 93.834 +/- 908.36\n",
    "  x0**4 + x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-3,  accuracy: 0.190000, mse: 0.07634 +/- 0.051586\n",
    "  x0**5 + x0**4 + x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-4,  accuracy: 0.000000, mse: 0.89156 +/- 4.9355\n",
    "  x0**6 + x0**5 + x0**4 + x0**3 + x0**2 + x0 \n",
    "\n",
    "  Nguyen-5,  accuracy: 0.000000, mse: 61.043 +/- 495.85\n",
    "  sin(x0**2)*cos(x0) - 1 \n",
    "\n",
    "  Nguyen-6,  accuracy: 0.000000, mse: 0.34162 +/- 0.18094\n",
    "  sin(x0) + sin(x0**2 + x0) \n",
    "\n",
    "  Nguyen-7,  accuracy: 0.000000, mse: nan +/- nan\n",
    "  log(x0 + 1) + log(x0**2 + 1) \n",
    "\n",
    "  Nguyen-8,  accuracy: 0.000000, mse: 0.39772 +/- 0.018983\n",
    "  sqrt(x0) \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
